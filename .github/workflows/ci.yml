name: CI - Epic 0 Quality Gates

on:
  pull_request:
    branches:
      - main
      - develop
  push:
    branches:
      - main
      - develop
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"

jobs:
  quality-gates:
    name: Epic 0 Platform Quality Gates
    runs-on: ubuntu-latest
    
    # CRITICAL: Fail fast if quality gates don't pass
    # This job MUST pass before PR can be merged
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-mock
      
      - name: Set up test environment variables
        env:
          FRONTEGG_CLIENT_ID: "test-client-id"
          FRONTEGG_CLIENT_SECRET: "test-client-secret"
          DATABASE_URL: "sqlite:///:memory:"
          REDIS_URL: "redis://localhost:6379"
          ENV: "test"
        run: |
          echo "Test environment variables configured"
      
      - name: Run Epic 0 Quality Gate Tests
        working-directory: ./backend
        env:
          FRONTEGG_CLIENT_ID: "test-client-id"
          FRONTEGG_CLIENT_SECRET: "test-client-secret"
          DATABASE_URL: "sqlite:///:memory:"
          REDIS_URL: "redis://localhost:6379"
          ENV: "test"
          PYTHONPATH: "${{ github.workspace }}/backend"
        run: |
          echo "=========================================="
          echo "Running Epic 0 Quality Gate Tests"
          echo "=========================================="
          pytest src/tests/platform/test_platform_gate.py \
            -v \
            --tb=short \
            --strict-markers \
            --disable-warnings \
            -m "not slow" || exit 1
      
      - name: Run Tenant Isolation Tests
        working-directory: ./backend
        env:
          FRONTEGG_CLIENT_ID: "test-client-id"
          FRONTEGG_CLIENT_SECRET: "test-client-secret"
          DATABASE_URL: "sqlite:///:memory:"
          REDIS_URL: "redis://localhost:6379"
          ENV: "test"
          PYTHONPATH: "${{ github.workspace }}/backend"
        run: |
          echo "=========================================="
          echo "Running Tenant Isolation Tests"
          echo "=========================================="
          pytest src/tests/platform/test_tenant_isolation.py \
            -v \
            --tb=short \
            --strict-markers \
            --disable-warnings || exit 1
      
      - name: Quality Gate Summary
        if: always()
        run: |
          echo "=========================================="
          echo "Epic 0 Quality Gate Test Results"
          echo "=========================================="
          echo "✓ Tenant Isolation: Verified"
          echo "✓ RBAC Enforcement: Verified"
          echo "✓ Secrets Redaction: Verified"
          echo "✓ Audit Logging: Verified"
          echo "✓ Feature Flag Kill Switch: Verified"
          echo ""
          echo "All quality gates must pass for PR merge."
      
      - name: Fail if tests failed
        if: failure()
        run: |
          echo "::error::Epic 0 Quality Gates FAILED"
          echo "::error::PR merge is BLOCKED until all tests pass"
          echo "::error::Review test output above for details"
          exit 1

  # Additional job for full platform test suite
  platform-tests:
    name: Full Platform Test Suite
    runs-on: ubuntu-latest
    needs: [quality-gates, dbt-validation]  # Only run if quality gates and dbt validation pass
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-mock
      
      - name: Run all platform tests
        working-directory: ./backend
        env:
          FRONTEGG_CLIENT_ID: "test-client-id"
          FRONTEGG_CLIENT_SECRET: "test-client-secret"
          DATABASE_URL: "sqlite:///:memory:"
          REDIS_URL: "redis://localhost:6379"
          ENV: "test"
          PYTHONPATH: "${{ github.workspace }}/backend"
        run: |
          pytest src/tests/platform/ \
            -v \
            --tb=short \
            --cov=src/platform \
            --cov=src/repositories \
            --cov-report=term-missing \
            --cov-report=xml || exit 1
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: ./backend/coverage.xml
          flags: platform
          name: platform-tests

  # Billing regression tests with ephemeral database
  billing-regression-tests:
    name: Billing Regression Tests
    runs-on: ubuntu-latest
    needs: quality-gates  # Only run if quality gates pass

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_billing_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-mock pytest-cov pytest-timeout

      - name: Run Billing Regression Tests
        working-directory: ./backend
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/test_billing_db"
          SHOPIFY_API_SECRET: "test-webhook-secret-for-hmac"
          SHOPIFY_BILLING_TEST_MODE: "true"
          FRONTEGG_CLIENT_ID: "test-client-id"
          FRONTEGG_CLIENT_SECRET: "test-client-secret"
          REDIS_URL: "redis://localhost:6379"
          ENV: "test"
          PYTHONPATH: "${{ github.workspace }}/backend"
        run: |
          echo "=========================================="
          echo "Running Billing Regression Tests"
          echo "=========================================="
          pytest src/tests/regression/test_billing_regression.py \
            -v \
            --tb=short \
            -m "regression" \
            --timeout=600 \
            --cov=src/services/billing_service \
            --cov=src/api/routes/webhooks_shopify \
            --cov=src/jobs/reconcile_subscriptions \
            --cov-report=term-missing || exit 1

      - name: Run Raw Warehouse RLS Tests
        working-directory: ./backend
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/test_billing_db"
          FRONTEGG_CLIENT_ID: "test-client-id"
          FRONTEGG_CLIENT_SECRET: "test-client-secret"
          ENV: "test"
          PYTHONPATH: "${{ github.workspace }}/backend"
        run: |
          echo "=========================================="
          echo "Running Raw Warehouse RLS Isolation Tests"
          echo "=========================================="
          pytest src/tests/platform/test_raw_rls.py \
            -v \
            --tb=short \
            --timeout=300 || exit 1

      - name: Billing Regression Summary
        if: always()
        run: |
          echo "=========================================="
          echo "Billing Regression Test Results"
          echo "=========================================="
          echo "Test Coverage:"
          echo "  1. Checkout URL Happy Path"
          echo "  2. Webhook Subscription Activation"
          echo "  3. Plan Upgrade Flow"
          echo "  4. Cancellation Flow"
          echo "  5. Failed Payment Handling"
          echo "  6. Reconciliation Drift Correction"
          echo "  7. HMAC Security Verification"
          echo "  8. Cross-Tenant Isolation"
          echo ""
          echo "Raw Warehouse RLS Test Coverage:"
          echo "  1. Tenant sees only own data"
          echo "  2. Cross-tenant access blocked"
          echo "  3. Empty context returns no data"
          echo "  4. SQL injection blocked"
          echo "  5. Context switching isolation"

  # dbt validation: validates dbt models, schema, and data quality
  dbt-validation:
    name: dbt Validation
    runs-on: ubuntu-latest
    needs: quality-gates  # Only run if quality gates pass

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_dbt_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dbt dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install dbt-postgres

      - name: Configure dbt profiles
        working-directory: ./analytics
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
          DB_SSLMODE: disable
        run: |
          echo "Creating profiles.yml from template..."
          cp profiles.yml.example profiles.yml
          echo "dbt profiles configured via environment variables"
          echo "Profiles file location: $(pwd)/profiles.yml"

      - name: Run dbt debug
        working-directory: ./analytics
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
          DB_SSLMODE: disable
        run: |
          echo "=========================================="
          echo "Running dbt debug"
          echo "=========================================="
          dbt debug --profiles-dir . --project-dir . || exit 1

      - name: Install dbt packages
        working-directory: ./analytics
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
          DB_SSLMODE: disable
        run: |
          echo "=========================================="
          echo "Installing dbt packages"
          echo "=========================================="
          dbt deps --profiles-dir . --project-dir . || exit 1

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Create dbt source tables
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
        run: |
          echo "=========================================="
          echo "Creating dbt source schemas and tables"
          echo "=========================================="
          psql "postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}" -v ON_ERROR_STOP=1 <<'SQL'
          create schema if not exists platform;
          create schema if not exists airbyte_raw;

          create table if not exists platform.tenant_airbyte_connections (
            airbyte_connection_id text not null,
            tenant_id text not null,
            source_type text not null,
            connection_name text,
            status text not null,
            is_enabled boolean not null,
            configuration jsonb default '{}'::jsonb
          );

          create table if not exists airbyte_raw._airbyte_raw_shopify_orders (
            _airbyte_ab_id text,
            _airbyte_emitted_at timestamptz,
            _airbyte_data jsonb
          );

          create table if not exists airbyte_raw._airbyte_raw_shopify_customers (
            _airbyte_ab_id text,
            _airbyte_emitted_at timestamptz,
            _airbyte_data jsonb
          );

          create table if not exists airbyte_raw._airbyte_raw_meta_ads (
            _airbyte_ab_id text,
            _airbyte_emitted_at timestamptz,
            _airbyte_data jsonb
          );

          create table if not exists airbyte_raw._airbyte_raw_google_ads (
            _airbyte_ab_id text,
            _airbyte_emitted_at timestamptz,
            _airbyte_data jsonb
          );

          -- Insert test tenant connection with shop_domain configuration
          insert into platform.tenant_airbyte_connections
            (airbyte_connection_id, tenant_id, source_type, connection_name, status, is_enabled, configuration)
          values
            ('airbyte-conn-shopify-1', 'tenant-test-123', 'shopify', 'Test Store - Shopify', 'active', true, '{"shop_domain": "test-store.myshopify.com"}'::jsonb),
            ('airbyte-conn-meta-1', 'tenant-test-123', 'source-facebook-marketing', 'Meta Ads', 'active', true, '{}'::jsonb),
            ('airbyte-conn-google-1', 'tenant-test-123', 'source-google-ads', 'Google Ads', 'active', true, '{}'::jsonb);

          -- Insert test Shopify orders with shop_url
          insert into airbyte_raw._airbyte_raw_shopify_orders
            (_airbyte_ab_id, _airbyte_emitted_at, _airbyte_data)
          values
            ('order-1', '2024-01-15 10:00:00+00', '{"id": "gid://shopify/Order/12345", "name": "#1001", "order_number": "1001", "email": "customer1@example.com", "created_at": "2024-01-15T10:00:00Z", "updated_at": "2024-01-15T10:05:00Z", "financial_status": "paid", "fulfillment_status": "fulfilled", "total_price": "99.99", "subtotal_price": "89.99", "total_tax": "10.00", "currency": "USD", "customer": {"id": "gid://shopify/Customer/111"}, "tags": "test,new-customer", "note": "Test order", "shop_url": "https://test-store.myshopify.com"}'::jsonb),
            ('order-2', '2024-01-16 11:00:00+00', '{"id": "gid://shopify/Order/12346", "name": "#1002", "order_number": "1002", "email": "customer2@example.com", "created_at": "2024-01-16T11:00:00Z", "updated_at": "2024-01-16T11:10:00Z", "financial_status": "paid", "fulfillment_status": "fulfilled", "total_price": "149.50", "subtotal_price": "135.00", "total_tax": "14.50", "currency": "USD", "customer": {"id": "gid://shopify/Customer/222"}, "tags": "vip", "shop_url": "https://test-store.myshopify.com"}'::jsonb);

          -- Insert test Shopify customers with shop_url
          insert into airbyte_raw._airbyte_raw_shopify_customers
            (_airbyte_ab_id, _airbyte_emitted_at, _airbyte_data)
          values
            ('customer-1', '2024-01-10 09:00:00+00', '{"id": "gid://shopify/Customer/111", "email": "customer1@example.com", "first_name": "John", "last_name": "Doe", "phone": "+1234567890", "created_at": "2024-01-10T09:00:00Z", "updated_at": "2024-01-15T10:00:00Z", "accepts_marketing": "true", "verified_email": "true", "orders_count": "5", "total_spent": "499.99", "currency": "USD", "state": "enabled", "default_address": {"country": "US", "city": "New York"}, "shop_url": "https://test-store.myshopify.com"}'::jsonb),
            ('customer-2', '2024-01-11 10:00:00+00', '{"id": "gid://shopify/Customer/222", "email": "customer2@example.com", "first_name": "Jane", "last_name": "Smith", "created_at": "2024-01-11T10:00:00Z", "updated_at": "2024-01-16T11:00:00Z", "accepts_marketing": "false", "verified_email": "1", "orders_count": "3", "total_spent": "299.50", "currency": "USD", "state": "enabled", "default_address": {"country": "CA", "city": "Toronto"}, "shop_url": "https://test-store.myshopify.com"}'::jsonb);

          -- Insert test Meta Ads data
          insert into airbyte_raw._airbyte_raw_meta_ads
            (_airbyte_ab_id, _airbyte_emitted_at, _airbyte_data)
          values
            ('meta-1', '2024-01-15 08:00:00+00', '{"account_id": "act_123456", "campaign_id": "120330000000000001", "adset_id": "120330000000000002", "ad_id": "120330000000000003", "date_start": "2024-01-15", "date_stop": "2024-01-15", "spend": "25.50", "impressions": "5000", "clicks": "150", "conversions": "5.0", "currency": "USD", "campaign_name": "Test Campaign", "adset_name": "Test Adset", "ad_name": "Test Ad", "objective": "CONVERSIONS"}'::jsonb);

          -- Insert test Google Ads data
          insert into airbyte_raw._airbyte_raw_google_ads
            (_airbyte_ab_id, _airbyte_emitted_at, _airbyte_data)
          values
            ('google-1', '2024-01-15 08:00:00+00', '{"customer_id": "1234567890", "campaign_id": "987654321", "ad_group_id": "111222333", "ad_id": "444555666", "date": "2024-01-15", "cost_micros": "25500000", "impressions": "5000", "clicks": "150", "conversions": "5.0", "conversion_value": "250.00", "currency_code": "USD", "campaign_name": "Test Campaign", "ad_group_name": "Test Ad Group", "ad_type": "SEARCH", "device": "DESKTOP", "network": "SEARCH"}'::jsonb);
          SQL

      - name: Run dbt compile
        working-directory: ./analytics
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
          DB_SSLMODE: disable
        run: |
          echo "=========================================="
          echo "Compiling dbt models"
          echo "=========================================="
          dbt compile --profiles-dir . --project-dir . || exit 1

      - name: Run dbt run (all models)
        working-directory: ./analytics
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
          DB_SSLMODE: disable
        run: |
          echo "=========================================="
          echo "Running all dbt models"
          echo "=========================================="
          dbt run --profiles-dir . --project-dir . || exit 1

      - name: Run dbt test
        working-directory: ./analytics
        env:
          DB_HOST: localhost
          DB_USER: test
          DB_PASSWORD: test
          DB_PORT: 5432
          DB_NAME: test_dbt_db
          DB_SSLMODE: disable
        run: |
          echo "=========================================="
          echo "Running dbt tests"
          echo "=========================================="
          dbt test --profiles-dir . --project-dir . || exit 1

      - name: dbt Validation Summary
        if: always()
        run: |
          echo "=========================================="
          echo "dbt Validation Results"
          echo "=========================================="
          echo "✓ dbt connection verified"
          echo "✓ Models compiled successfully"
          echo "✓ All models built"
          echo "✓ Data quality tests passed"
          echo ""
          echo "Schema/logic changes validated before merge."

  # Block PR merge if quality gates fail
  pr-check:
    name: PR Merge Gate
    runs-on: ubuntu-latest
    needs: [quality-gates, platform-tests, billing-regression-tests, dbt-validation]
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Verify quality gates passed
        run: |
          echo "✓ All Epic 0 Quality Gates passed"
          echo "✓ PR is eligible for merge"
          echo ""
          echo "Next steps:"
          echo "1. Code review approval"
          echo "2. Merge to main"
          echo "3. Auto-deploy to Render (if configured)"